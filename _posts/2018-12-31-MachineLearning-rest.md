---
layout:     post                    # 使用的布局（不需要改）
title:      MachineLearning-rest     # 标题 
subtitle:   机器学习-随笔记           #副标题
date:       2018-12-31              # 时间
author:     ZYM                     # 作者
header-img: img/first.jpg           #这篇文章标题背景图片
catalog: true                       # 是否归档
---

# MachineLearning

## 神经网络

有人曾做实验，将视觉的输入神经连到大脑的其他区域，发现依旧可以有视觉，猜测神经元的链连接经过刺激可以适应各种任务，是否也有一种结构可以模仿此类结构？  

神经网络常由输入层、隐藏层、输出层构成，输入层输入数据的特征，隐藏层对特征进行处理，最后传输到输出层，得到结果。  

隐藏层是进行处理预测的关键，它可以有很多层，每层将上一层的特征数据处理后传到下一层，每层传输之间都有带参数的函数关系，最后一层传输到输出层上。如判断天气的输出层可有3个，对应晴天、阴天、雨天，最后根据输出预测  

## 支持向量机

### 不带核函数

不带核函数的支持向量机类似逻辑回归，只不过其代价函数变化了，在接近正确结果时不再是缓慢变为0，而是类似线性接近0，在越过正确结果后变为0，目的是尽可能的使预测函数预测出正确结果，表现在预测结果可能很大，代表为1的概率很大，也代表了其大间距分类器的思想，即尽可能将两种结果用一个距离两方间距都较大的分界线分割开。  

### 核函数

带核函数即选定一些地标，计算输入特征到这些特征的“距离”作为代价函数，最小化代价函数后，根据预测函数值预测结果  

## 聚类

聚类，顾名思义，即将一些分散点聚为n簇  

常用KMeans聚类，即通过设立初始中心点，根据距离不断迭代更新中心，最后聚为K簇（k值通常在开始前已确定，也有可以不指定簇个数的聚类方法）  

若不确定要聚几类，如不知道数据中有几类，可以用“肘部法则”，进行聚类n到m簇的尝试，在簇数增加而总距离代价不太变化时就是合适的距离数。  

## 异常检测

## 降维

### 主成分分析

## 在线学习